[{"title":"召回系统在海拍客的实践","date":"2023-02-20T01:51:17.000Z","path":"2023/02/20/yuque/tnro7ekghmfx200c/","text":"前言推荐系统通常可以分为召回、粗排、精排、重排四个阶段，召回主要是根据不同策略或模型从海量的物品库中快速筛选出一小部分用户可能感兴趣的物品，交由排序模型来精准地完成个性化排序，本文主要阐述召回在算法侧的工作原理以及召回系统工程侧落地实践。 召回算法目前算法团队在使用传统算法如 ItemCF、Swing 的基础上，也在不断尝试在召回中应用深度模型，下面章节介绍目前算法团队使用到的几种典型召回算法原理，实际的模型会更复杂但原理大同小异。 协同过滤作为在推荐系统召回中最基本的一种算法，系统过滤主要分为两大类 基于用户的协同过滤算法(UserCF) 基于物品的协同过滤算法(ItemCF) 基于用户的协同过滤简单的说基于用户的协同过滤就是找到与你相似的用户，将相似用户交互过的商品推荐给你。基于用户的协同过滤核心在于计算用户的相似度，以一个简单的例子演示该算法假设我们在做首页商品推荐，用户 A 点击的商品集合为 M，用户 B 点击的商品集合为 N,那么用户 A 和用户 B 的相似度可以通过如下公式计算 image.png 如用户 A 点击过的商品集合 M &#x3D; {a,b,c,d} , 用户 B 点击过的商品集合 N&#x3D;{a,b,c,d,e,f} ，所以用户 A 和用户 B 的相似度为 2&#x2F;3，用户 C 点击过的商品集合为{a,b,c} ，用户 D 点击过的商品集合为{a,b}，此处我们人为定义相似度阈值为 0.5，那么与用户 A 相似的用户为用户 B 和用户 C，那么可以给用户 A 推荐商品{e,f}，给用户 C 推荐{d,e,f}。 这里只是展示了一种比较简单粗暴的方法，想要得到更好的推荐效果可以改进相似度的计算方法，这边不作深究。 基于物品的协同过滤简单来说基于物品的协同过滤就是根据用户对商品的交互历史，推荐该商品相似的其他商品。基于物品的协同过滤同样需要计算物品的相似度，以一个简单的例子演示该算法假设喜欢物品 a 的用户数量为 N(a)，喜欢物品 b 的用户数量为 N(b) ，那么物品 a 和物品 b 的相似度可以使用如下公式表示 image.png 假设用户对商品的喜好如下表所示 商品 a 商品 b 商品 c 商品 d 用户 A [x] | [x] | [x] | || 用户 B || [x] | [x] | [x] || 用户 C | | | [x] | [x] | 那么根据上述的相似度计算公式可以得到ab 相似度为 0.71 ，ac 相似度为 0.58，bc 相似度为 0.82，cd 相似度为 0.82我们人为假定某个用户对商品 a 有购买行为兴趣度为 10，对 b 商品有点击行为兴趣度为 5，那么我们可以得到该用户对商品 c 的兴趣度为 10 _ 0.58 + 5 _ 0.82 &#x3D; 9.9，对 d 的兴趣度为 0 ，因此可以给该用户推荐商品 c image.png 双塔模型双塔模型是一种在推荐领域召回、粗排阶段被广泛使用的深度学习模型，其结构非常简单如下图所示 image.png 左侧是 User 塔，右侧是 Item 塔，可将特征拆分为两大类：用户相关特征（用户基本信息、群体统计属性以及行为过的 Item 序列等）与 Item 相关特征（Item 基本信息、属性信息等），原则上，Context 上下文特征可以放入用户侧塔。对于这两个塔本身，则是经典的 DNN 模型，从特征 OneHot 到特征 Embedding，再经过几层 MLP 隐层，两个塔分别输出用户 Embedding 和 Item Embedding 编码。训练阶段，User Embedding 和 Item Embedding 做内积或者 Cosine 相似度计算，使得用户和正例 Item 在 Embedding 空间更接近，和负例 Item 在 Embedding 空间距离拉远，损失函数则可用标准交叉熵损失。在线服务阶段，对于海量的 Item 集合，可以通过 Item 侧塔，离线将所有 Item 转化成 Embedding，并存储进 ANN 检索系统如 Faiss 以供查询。当一个用户进行请求时，将用户最新行为过的 Item 作为用户侧塔的输入，然后通过用户侧塔打出 User Embedding，从 Faiss 库里拉取相似性得分 Top K 的 Item，做为个性化召回结果这种模式。这样也可以实时地体现用户即时兴趣的变化，这是特征实时的角度，做起来相对简单。 image.png 本章小结目前算法侧通过离线的方式训练召回数据，存储到对应的数据源中，工程侧需要通过召回配置完成多路召回-去重-过滤-融合的操作，将召回结果送到下一阶段进行个性化排序，对整个推荐链路而言，召回要求快，排序要求准，所以对召回系统的要求是稳定低延迟。 image.png 召回工程海拍客推荐目前服务触达、首页、搜索激活页、支付成功页、 我的页面等多个场景，涵盖了购前、购中、购后等多个不同阶段。如上面所述，商品召回作为推荐的第一步在整个推荐流程中起到了举足轻重的作用，直接影响了返回物料的质量，而合理的召回工程架构也一定程度上影响业务和算法迭代的速度与质量。 召回初代架构由于业务的特殊性以及诸多历史遗留问题，在之前海拍客的推荐架构中各业务系统需要各自完成商品召回，再按需调用精排服务完成商品排序等后续操作，召回数据源又各有不同，如触达业务使用了 MySQL 作为召回数据源，推荐业务使用了 Redis 作为主要的召回数据源，所涉及到的架构大致如下图所示 image.png 架构局限性这种架构在业务的迭代中也逐渐出现各种弊端 职责不清晰， 从整个推荐域看，这种架构增加了业务系统复杂度使得业务系统过重，系统和系统之间架构职责不清晰 扩展性差，依赖各业务系统各自完成召回动作，而商品召回本身并不是一个简单动作，需要完成召回-过滤-融合等一系列动作。除此以外，数据源的新增变更、数据结构的变化带来的适配工作也是一个让人头疼的问题 召回配置难，这一点是对算法同学而言的，原有架构缺少一个统一的召回配置平台，AB 实验的进行和验证受到影响，妨碍算法迭代效率提升 稳定性难保障，对平台开发同学而言，日常需要监控依赖数据源、召回的各个阶段，如数据源平均 rt，各阶段平均 rt、超时率，召回整体的兜底率等指标，业务系统越多越不利于监控，系统的稳定性也会大打折扣 召回系统设计基于如上所述的诸多缺点，我们着手完成了推荐召回的服务切分，使得触达、首页推荐、购后等多个场景的推荐业务召回部分能够得到统一 主体设计一般来说，整个召回阶段主要完成多路召回-过滤-去重-融合几个步骤，大致的作用如下 多路召回，根据配置采用不同的召回策略从不同的数据源中获取物料，原则上多路召回尽可能多的返回用户可能有兴趣的物料，通常会根据每路召回的后验表现来设置配比。 去重，这一步主要是针对每一路召回而言，通常只是简单的根据商品 id 或者一些简单属性去重，避免因为数据源清洗问题导致的重复曝光。 过滤，通常会存在一些不同的过滤规则，如用户维度的曝光过滤、点击过滤、购买过滤等，也可能是基于风控规则的过滤，如卖家作弊等处罚、黄图恶心图等过滤。 融合，多路召回的物料根据需要进行合并，截断选取若干物料进入下一阶段，可以按照召回策略优先级融合，也可以是多路召回投票融合，也可以是通过物料的指标权重融合。 针对上述召回系统的几个步骤和特性，我们设计了如下的系统架构，整个召回系统大体上可以分为三层，召回配置层、召回引擎层、数据依赖层。 image.png 召回配置层 召回配置层主要面向算法同学，旨在让算法同学方便快捷地进行召回层配置进行 AB 实验和后续的结果验证，在实现上，主要借助 Disconf 作为配置中心，在引擎层做 AB 分流、召回配置解析等前置操作。 召回引擎层 召回引擎层采用模块化设计，通过召回配置实现模块和任务节点的动态化编排，同时通过插件化思想提供了异构数据源的支持，大大降低了新增数据源的成本。在稳定性保障上，由于采用了模块-任务节点的设计，能够很好地实现多维度的监控，如场景-模块维度的 rt 监控、失败率监控，场景-任务节点维度的超时率监控，场景维度的兜底率、无结果率监控等，同时配合钉钉告警实现问题的早发现早止血。 召回存储层 召回存储层主要面向异构数据源设计，前面提到因为历史原因现有的召回数据源结构和存储介质都存在差异以满足不同业务系统的诉求，因此在改造召回系统的过程中需要充分考虑数据存储的问题，如首页推荐等场景召回数据结构相对简单，需要满足低延迟诉求所以一直以来优先考虑 Redis, 又如触达算法召回数据结构复杂，包含属性多，数据量大用 MySQL 或者 MongoDB 更合适些，又如后续业务可能存在向量召回的场景，使用 ElasticSearch 或者调用 faiss 服务更合适，因此必须要考虑异构数据源的接入便捷性。 实现细节这一节主要介绍下召回引擎部分的一些实现细节以及踩过的一些坑，整个召回召回引擎调度如下图所示 image.png 模块化设计 如上述，整个召回过程中大体经过了多路召回-去重-过滤-融合等步骤。在设计上可以将各个步骤封装成独立的模块(module)，AB 分流获取门店对应的召回配置后，根据配置编排所需要的模块完成调度。而模块和模块之间又可能存在依赖关系，如在召回系统中各模块之间是串行的，而在一些系统中存在模块并发执行的需求，所以在设计之初设计了如下结构来做兼容，简单来说同一个列表内多个模块并发执行，不同列表的模块串行执行。 image.png 在模块内，抽象出任务节点(TaskNode)，如在多路召回模块中，每一路召回相当于一个任务节点，彼此并发执行，又比如在过滤模块中，每一种过滤策略可以当做一个任务节点获取待过滤数据。通过任务节点并发的方式可以有效降低 RT,相较于之前串行召回的方式平均减少 RT 约 16%。如下代码大致演示了模块内任务节点执行的实现。 image.png 1234567891011121314151617181920212223242526272829303132/** * 模块执行只需要执行任务列表中的任务即可 * 任务列表中的任务先暂时都并发执行 后面可以支持并发和顺序两种模式 * 即 [[A,B],[C]] A、B并发执行完成后再执行C * * @param requestContext 召回请求上下文 * @return recallModuleResultDto 召回模块结果对象 */@Overridepublic ModuleResult invoke(RequestContext requestContext) &#123; RecallStrategyConfig recallStrategyConfig = requestContext.getRecallStrategyConfig(); if (recallStrategyConfig == null) &#123; return null; &#125; ModuleResult moduleResult = new ModuleResult(); moduleResult.setTaskResultList(new ArrayList&lt;&gt;()); if (CollectionUtils.isEmpty(this.taskList)) &#123; return moduleResult; &#125; // 并发执行任务列表中的任务 使用arrayList保留任务原始的顺序 List&lt;Tuple&lt;TaskNode, CompletableFuture&lt;TaskResult&gt;&gt;&gt; tupleList = new ArrayList&lt;&gt;(); for (TaskNode taskNode : taskList) &#123; CompletableFuture&lt;TaskResult&gt; future = CompletableFuture.supplyAsync(() -&gt; taskNode.invoke(requestContext), ThreadUtil.executor); tupleList.add(new Tuple&lt;&gt;(taskNode, future)); &#125; // 结果获取 省略... return moduleResult;&#125; 模块内多个任务节点并发执行有一些需要关注的点，在实现中可能需要特别关注。 任务节点超时处理， 首先任务节点必须配置超时时间，避免因为某一个任务节点引起的服务雪崩，其次不同的任务节点其超时时间可以根据经验做配置化，如多路召回中 MongoDB 和 Redis 的超时时间可以根据监控做动态化调整，再比如对于无执行先后顺序要求的任务节点可以适当调整获取结果顺序以避免空结果等。 召回结果在不同阶段的传递，在目前的召回引擎实现中采用了上下文的方式传递召回中间结果，上下文中会保存不同阶段的模块结果(其中包含各阶段的召回结果)，保存不同阶段召回结果即每个阶段召回结果均为深拷贝以避免对上一个模块结果的破坏。 空结果处理， 在实际运行中可能存在各种情况导致召回结果为空，此时需要进行服务端兜底召回，除此以外当常规召回数量不够也需要使用兜底数据补召回，兜底召回数据请求实际也需要权衡，目前的实现中把兜底召回作为一路召回在多路并发召回阶段执行，通过多一次 IO 来降低服务的总 RT(兜底召回不一定被使用) 异构数据源支持 召回引擎提供了对多种数据源的支持，目前已支持如 Redis、MySQL、MongoDB、RPC 等多种数据源。以触达算法召回为例，数据量大且字段属性多，非常适合以 MongoDB 作为存储数据源，而首页推荐、购后推荐等场景的召回数据大多结构简单且要求召回速度快，因此以 Redis 作为存储数据源更合适。常规的单路召回需要经过获取数据-去重-截断-类型转换等步骤，其中获取数据和类型转换需要根据数据源类型做适配，因此在设计之初采用插件的方式支持异构数据源，只要实现几个简单方法就可以完成数据源的新增，如下代码大致展示了数据源插件的抽象定义 1234567891011121314151617public abstract class AbstractRecaller&lt;OriginType, ResultType&gt; implements Recaller&lt;OriginType, ResultType&gt; &#123; //部分代码省略 @Override public ResultType recall(RequestContext requestContext, RecallSourceConfig recallSourceConfig) &#123; // 获取数据源数据 OriginType originData = fetch(requestContext, recallSourceConfig); // 去重 originData = distinct(originData); // 截断 originData = cut(originData, recallSourceConfig.getLen()); // 转换 ResultType result = convert(originData, recallSourceConfig); return result; &#125;&#125; 以一个实际的单路召回为例，召回策略配置如下，表示该路召回策略存储数据源为 MongoDB，召回类型为 s2i，召回的主键标识为 actnew_sign,同时需要返回对应文档的指定字段 12345mongo_act_new_sign: dataSource: mongo fields: itemId,shopId,feature,rankNum,orderedDays key: act_new_sign_ type: recall_s2i 在运行的过程中召回引擎先会根据召回类型、绑定的数据源元信息等匹配对应的召回器 Recaller, 召回器的注册使用自定义注解@AiRecaller 完成，如下代码即为以 MongoDB 作为数据源的接入方式。 123456789101112131415161718192021222324252627282930@AiRecaller( name = \"touchMongoRecaller\", dataSourceType = RecallDataSourceType.mongo, recallTypes = &#123;RecallType.recall_s2i&#125;, dbName = \"ai_recall\", tableName = \"ai_touch\")public class TouchMongoRecaller extends AbstractRecaller&lt;List&lt;TouchRecallDo&gt;, TriggerResult&gt; &#123; @Resource private MongoTemplate mongoTemplate; @Override public List&lt;TouchRecallDo&gt; fetch(RequestContext requestContext, RecallSourceConfig recallSourceConfig) &#123; String sceneId = requestContext.getRecallReq().getSceneId(); String recallKey = recallSourceConfig.getKey(); String shopId = requestContext.getRecallReq().getShopId(); // 查询 List&lt;TouchRecallDo&gt; touchRecallDos = null; Query query = new Query(); // TODO 这边可以结合管理后台实现查询条件的配置化 query.addCriteria(Criteria.where(\"shop_id\").is(shopId)) .addCriteria(Criteria.where(\"recall_key\").is(recallKey)) .with(Sort.by(Sort.Order.asc(\"rank_num\"))); try &#123; touchRecallDos = mongoTemplate.find(query, TouchRecallDo.class); &#125; catch (Exception e) &#123; logger.error(\"[TouchMongoRecaller-fetch] sceneId:&#123;&#125; recallKey:&#123;&#125; shopId:&#123;&#125; exception cause:\", sceneId, recallKey, shopId, e); &#125; return touchRecallDos; &#125; 需要说明的是目前召回引擎多以离线方式计算落库，实时召回也多以用户实时 Query 等作为 trigger，但现有的召回系统架构可以快速支持如基于向量的实时召回等方式，这也是后续召回引擎一个迭代的方向。 总结和展望如上文提及，目前算法侧的召回数据均以离线方式产出落库，因此对实时特征的利用相对不足。后续召回引擎可以结合特征平台建设，尝试基于 ElasticSearch 或者 Faiss 的在线检索召回服务。 文献引用推荐系统技术演进趋势：从召回到排序再到重排SENet 双塔模型：在推荐领域召回粗排的应用及其它","tags":[]},{"title":"DataX入门","date":"2023-02-20T01:51:06.000Z","path":"2023/02/20/yuque/vlbuedodq51kv4gd/","text":"安装方式二进制安装使用二进制包 http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz 编译安装1234567891011git clone https://github.com/alibaba/DataX.git// 1.编译mvn clean install -Dmaven.skip.test=true// 缺少hitsdb-client 0.4.0-SNAPSHOT版本主仓库中没有...// 2.找到该项目并打包git clone https://github.com/aliyun/aliyun-tsdb-java-sdk.gitgit checkout -b 0.4 remotes/origin/release/0.4.0mvn clean install Dmaven.test.skip=true// 重新编译DataXmvn clean install -Dmaven.skip.test=true 编译完成后结构如下图所示在 datax-core 项目的 target 中，其中 plugin 文件夹要手动添加所需要的插件，找 到编译好的插件直接拷贝到 datax-core 的 plugin 目录就可以了 image.png](https://cdn.nlark.com/yuque/0/2022/png/21378486/1649826933622-4feb4348-9009-43d5-90ad-4032fe87964b.png#clientId=u5917c856-b3cc-4&from=paste&height=510&id=u77c257a3&name=image.png&originHeight=1020&originWidth=2480&originalType=binary∶=1&rotation=0&showTitle=false&size=154744&status=done&style=none&taskId=u372f77e2-b6d0-40c8-96cf-b21db085723&title=&width=1240)![image.png 运行代码获取配置文件模板 image.png 配置文件修改12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&#123; \"job\": &#123; \"content\": [ &#123; \"reader\": &#123; \"name\": \"mysqlreader\", \"parameter\": &#123; \"column\": [ \"recall_key\", \"shop_id\", \"item_id\", \"ordered_days\", \"rank_num\", \"sync_date\", \"create_time\", \"edit_time\", \"feature\", \"extra\" ], \"connection\": [ &#123; \"jdbcUrl\": [ \"jdbc:mysql://rdsxt5l78bid42x9ddylc832.mysql.rds.aliyuncs.com:3306/algo\" ], \"table\": [\"sync_ai_match_recall_d\"] &#125; ], \"password\": \"yangtuojia001\", \"username\": \"yangtuojia001\", \"where\": \"\" &#125; &#125;, \"writer\": &#123; \"name\": \"mongodbwriter\", \"parameter\": &#123; \"address\": [\"127.0.0.1:27017\"], \"collectionName\": \"ai_touch\", \"column\": [ &#123; \"name\": \"recall_key\", \"type\": \"string\" &#125;, &#123; \"name\": \"shop_id\", \"type\": \"string\" &#125;, &#123; \"name\": \"item_id\", \"type\": \"long\" &#125;, &#123; \"name\": \"ordered_days\", \"type\": \"int\" &#125;, &#123; \"name\": \"rank_num\", \"type\": \"int\" &#125;, &#123; \"name\": \"sync_date\", \"type\": \"string\" &#125;, &#123; \"name\": \"create_time\", \"type\": \"date\" &#125;, &#123; \"name\": \"edit_time\", \"type\": \"date\" &#125;, &#123; \"name\": \"feature\", \"type\": \"object\" &#125;, &#123; \"name\": \"extra\", \"type\": \"object\" &#125; ], \"dbName\": \"ai_recall\", \"upsertInfo\": &#123; \"isUpsert\": \"true\", \"upsertKey\": \"recall_key,shop_id,item_id\" &#125;, \"userName\": \"\", \"userPassword\": \"\" &#125; &#125; &#125; ], \"setting\": &#123; \"speed\": &#123; \"channel\": \"2\" &#125; &#125; &#125;&#125; 启动任务python datax.py mysql2mongo.json 执行结果如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207DataX (DATAX-OPENSOURCE-3.0), From Alibaba !Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.2022-04-13 14:48:37.961 [main] INFO VMInfo - VMInfo# operatingSystem class =&gt; sun.management.OperatingSystemImpl2022-04-13 14:48:38.024 [main] INFO Engine - the machine info =&gt; osInfo: Oracle Corporation 1.8 25.211-b12 jvmInfo: Mac OS X x86_64 10.16 cpu num: 4 totalPhysicalMemory: -0.00G freePhysicalMemory: -0.00G maxFileDescriptorCount: -1 currentOpenFileDescriptorCount: -1 GC Names [PS MarkSweep, PS Scavenge] MEMORY_NAME | allocation_size | init_size PS Eden Space | 256.00MB | 256.00MB Code Cache | 240.00MB | 2.44MB Compressed Class Space | 1,024.00MB | 0.00MB PS Survivor Space | 42.50MB | 42.50MB PS Old Gen | 683.00MB | 683.00MB Metaspace | -0.00MB | 0.00MB2022-04-13 14:48:38.243 [main] INFO Engine -&#123; \"content\":[ &#123; \"reader\":&#123; \"name\":\"mysqlreader\", \"parameter\":&#123; \"column\":[ \"recall_key\", \"shop_id\", \"item_id\", \"ordered_days\", \"rank_num\", \"sync_date\", \"create_time\", \"edit_time\", \"feature\", \"extra\" ], \"connection\":[ &#123; \"jdbcUrl\":[ \"jdbc:mysql://rdsxt5l78bid42x9ddylc832.mysql.rds.aliyuncs.com:3306/algo\" ], \"table\":[ \"sync_ai_match_recall_d\" ] &#125; ], \"password\":\"*************\", \"username\":\"yangtuojia001\", \"where\":\"\" &#125; &#125;, \"writer\":&#123; \"name\":\"mongodbwriter\", \"parameter\":&#123; \"address\":[ \"127.0.0.1:27017\" ], \"collectionName\":\"ai_touch\", \"column\":[ &#123; \"name\":\"recall_key\", \"type\":\"string\" &#125;, &#123; \"name\":\"shop_id\", \"type\":\"string\" &#125;, &#123; \"name\":\"item_id\", \"type\":\"long\" &#125;, &#123; \"name\":\"ordered_days\", \"type\":\"int\" &#125;, &#123; \"name\":\"rank_num\", \"type\":\"int\" &#125;, &#123; \"name\":\"sync_date\", \"type\":\"string\" &#125;, &#123; \"name\":\"create_time\", \"type\":\"date\" &#125;, &#123; \"name\":\"edit_time\", \"type\":\"date\" &#125;, &#123; \"name\":\"feature\", \"type\":\"object\" &#125;, &#123; \"name\":\"extra\", \"type\":\"object\" &#125; ], \"dbName\":\"ai_recall\", \"upsertInfo\":&#123; \"isUpsert\":\"true\", \"upsertKey\":\"recall_key,shop_id,item_id\" &#125;, \"userName\":\"\", \"userPassword\":\"\" &#125; &#125; &#125; ], \"setting\":&#123; \"speed\":&#123; \"channel\":\"2\" &#125; &#125;&#125;2022-04-13 14:48:38.363 [main] WARN Engine - prioriy set to 0, because NumberFormatException, the value is: null2022-04-13 14:48:38.371 [main] INFO PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=02022-04-13 14:48:38.372 [main] INFO JobContainer - DataX jobContainer starts job.2022-04-13 14:48:38.392 [main] INFO JobContainer - Set jobId = 02022-04-13 14:48:39.993 [job-0] INFO OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://rdsxt5l78bid42x9ddylc832.mysql.rds.aliyuncs.com:3306/algo?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true.2022-04-13 14:48:40.074 [job-0] INFO OriginalConfPretreatmentUtil - table:[sync_ai_match_recall_d] has columns:[id,recall_key,shop_id,item_id,ordered_days,rank_num,sync_date,create_time,edit_time,feature,extra].2022-04-13 14:48:40.090 [job-0] INFO JobContainer - jobContainer starts to do prepare ...2022-04-13 14:48:40.092 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do prepare work .2022-04-13 14:48:40.092 [job-0] INFO JobContainer - DataX Writer.Job [mongodbwriter] do prepare work .2022-04-13 14:48:40.092 [job-0] INFO JobContainer - jobContainer starts to do split ...2022-04-13 14:48:40.093 [job-0] INFO JobContainer - Job set Channel-Number to 2 channels.2022-04-13 14:48:40.100 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.2022-04-13 14:48:40.105 [job-0] INFO JobContainer - DataX Writer.Job [mongodbwriter] splits to [1] tasks.2022-04-13 14:48:40.154 [job-0] INFO JobContainer - jobContainer starts to do schedule ...2022-04-13 14:48:40.161 [job-0] INFO JobContainer - Scheduler starts [1] taskGroups.2022-04-13 14:48:40.165 [job-0] INFO JobContainer - Running by standalone Mode.2022-04-13 14:48:40.182 [taskGroup-0] INFO TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.2022-04-13 14:48:40.188 [taskGroup-0] INFO Channel - Channel set byte_speed_limit to -1, No bps activated.2022-04-13 14:48:40.188 [taskGroup-0] INFO Channel - Channel set record_speed_limit to -1, No tps activated.2022-04-13 14:48:40.376 [0-0-0-reader] INFO CommonRdbmsReader$Task - Begin to read record by Sql: [select recall_key,shop_id,item_id,ordered_days,rank_num,sync_date,create_time,edit_time,feature,extra from sync_ai_match_recall_d] jdbcUrl:[jdbc:mysql://rdsxt5l78bid42x9ddylc832.mysql.rds.aliyuncs.com:3306/algo?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2022-04-13 14:48:40.380 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started2022-04-13 14:48:40.658 [0-0-0-writer] INFO cluster - Cluster created with settings &#123;hosts=[127.0.0.1:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500&#125;2022-04-13 14:48:40.659 [0-0-0-writer] INFO cluster - Adding discovered server 127.0.0.1:27017 to client view of cluster2022-04-13 14:48:40.799 [cluster-ClusterId&#123;value='62567248e4750c714d5dd1c4', description='null'&#125;-127.0.0.1:27017] INFO connection - Opened connection [connectionId&#123;localValue:1, serverValue:4&#125;] to 127.0.0.1:270172022-04-13 14:48:40.805 [cluster-ClusterId&#123;value='62567248e4750c714d5dd1c4', description='null'&#125;-127.0.0.1:27017] INFO cluster - Monitor thread successfully connected to server with description ServerDescription&#123;address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion&#123;versionList=[5, 0, 6]&#125;, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, roundTripTimeNanos=3738896&#125;2022-04-13 14:48:40.806 [cluster-ClusterId&#123;value='62567248e4750c714d5dd1c4', description='null'&#125;-127.0.0.1:27017] INFO cluster - Discovered cluster type of STANDALONE2022-04-13 14:48:41.205 [0-0-0-writer] INFO connection - Opened connection [connectionId&#123;localValue:2, serverValue:5&#125;] to 127.0.0.1:270172022-04-13 14:48:50.303 [job-0] INFO StandAloneJobContainerCommunicator - Total 0 records, 0 bytes | Speed 0B/s, 0 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.000s | All Task WaitReaderTime 0.000s | Percentage 0.00%2022-04-13 14:48:51.557 [0-0-0-reader] INFO CommonRdbmsReader$Task - Finished read record by Sql: [select recall_key,shop_id,item_id,ordered_days,rank_num,sync_date,create_time,edit_time,feature,extra from sync_ai_match_recall_d] jdbcUrl:[jdbc:mysql://rdsxt5l78bid42x9ddylc832.mysql.rds.aliyuncs.com:3306/algo?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2022-04-13 14:48:51.795 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":11,\"index\":0,\"rawData\":\"touch_milk_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"179677fd6b184036aa6dd1f2674aa36f\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":457777,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":2,\"index\":3,\"rawData\":10,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":8,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1638201600000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1638325337000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1638325337000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":0,\"index\":8,\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.800 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":11,\"index\":0,\"rawData\":\"touch_milk_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"0d949d31ecf046c98a36245196aae905\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":432738,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":2,\"index\":3,\"rawData\":10,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":8,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1638288000000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1638327833000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1647330418000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":0,\"index\":8,\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.801 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":15,\"index\":0,\"rawData\":\"act_repurchase_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"c85fe2aceb184925bef48c3e1a17278c\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":432736,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":2,\"index\":3,\"rawData\":10,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":8,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1638288000000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1638327941000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1647333079000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":87,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"1\\\",\\\"pay_gap\\\":\\\"87.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query\\\",\\\"itemType\\\":1&#125;&#125;\\n\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.802 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":13,\"index\":0,\"rawData\":\"act_new_sign_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"f7b33e25434c4acb933cda26776dff13\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":215007,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":2,\"index\":3,\"rawData\":10,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":8,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1638288000000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1638327943000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1647334138000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":89,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"471\\\",\\\"pay_gap\\\":\\\"87.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query\\\",\\\"itemType\\\":2&#125;&#125;\\n\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.805 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":13,\"index\":0,\"rawData\":\"act_new_sign_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"f7b33e25434c4acb933cda26776dff13\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":215709,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":2,\"index\":3,\"rawData\":10,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":8,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1638288000000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1638327958000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1647334154000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":40,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"480\\\",\\\"pay_gap\\\":\\\"87.0\\\"&#125;\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.808 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":12,\"index\":0,\"rawData\":\"touch_query_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"fedad34339be4d49afa0f5329cb6b228\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":415385,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":3,\"rawData\":0,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":4,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1648569600000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":73,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"0.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query_4\\\",\\\"itemType\\\":3&#125;&#125;\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.814 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":12,\"index\":0,\"rawData\":\"touch_query_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"fedad34339be4d49afa0f5329cb6b228\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":415385,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":3,\"rawData\":0,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":5,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1648569600000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":73,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"0.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query_5\\\",\\\"itemType\\\":1&#125;&#125;\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.819 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":12,\"index\":0,\"rawData\":\"touch_query_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"fedad34339be4d49afa0f5329cb6b228\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":297849,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":3,\"rawData\":0,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":2,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1648569600000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":73,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"0.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query_4\\\",\\\"itemType\\\":3&#125;&#125;\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.820 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据:&#123;\"message\":\"record's [5] column's type should be: string\",\"record\":[&#123;\"byteSize\":12,\"index\":0,\"rawData\":\"touch_query_\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":32,\"index\":1,\"rawData\":\"fedad34339be4d49afa0f5329cb6b228\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":6,\"index\":2,\"rawData\":463409,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":3,\"rawData\":0,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":1,\"index\":4,\"rawData\":1,\"type\":\"LONG\"&#125;,&#123;\"byteSize\":8,\"index\":5,\"rawData\":1648569600000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":6,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":8,\"index\":7,\"rawData\":1648680147000,\"type\":\"DATE\"&#125;,&#123;\"byteSize\":73,\"index\":8,\"rawData\":\"&#123;\\\"avg_order_amt\\\":\\\"0.0\\\",\\\"traceInfo\\\":&#123;\\\"recallType\\\":\\\"query_4\\\",\\\"itemType\\\":3&#125;&#125;\",\"type\":\"STRING\"&#125;,&#123;\"byteSize\":0,\"index\":9,\"type\":\"STRING\"&#125;],\"type\":\"writer\"&#125;2022-04-13 14:48:51.865 [0-0-0-writer] INFO connection - Closed connection [connectionId&#123;localValue:2, serverValue:5&#125;] to 127.0.0.1:27017 because the pool has been closed.2022-04-13 14:48:51.912 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[11546]ms2022-04-13 14:48:51.913 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] completed it's tasks.2022-04-13 14:49:00.313 [job-0] INFO StandAloneJobContainerCommunicator - Total 199722 records, 13382939 bytes | Speed 1.28MB/s, 19972 records/s | Error 16 records, 2145 bytes | All Task WaitWriterTime 9.765s | All Task WaitReaderTime 0.584s | Percentage 100.00%2022-04-13 14:49:00.313 [job-0] INFO AbstractScheduler - Scheduler accomplished all tasks.2022-04-13 14:49:00.314 [job-0] INFO JobContainer - DataX Writer.Job [mongodbwriter] do post work.2022-04-13 14:49:00.315 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do post work.2022-04-13 14:49:00.315 [job-0] INFO JobContainer - DataX jobId [0] completed successfully.2022-04-13 14:49:00.316 [job-0] INFO HookInvoker - No hook invoked, because base dir not exists or is a file: /Users/xiaoysec/Documents/DataX/core/target/datax/hook2022-04-13 14:49:00.320 [job-0] INFO JobContainer - [total cpu info] =&gt; averageCpu | maxDeltaCpu | minDeltaCpu -1.00% | -1.00% | -1.00% [total gc info] =&gt; NAME | totalGCCount | maxDeltaGCCount | minDeltaGCCount | totalGCTime | maxDeltaGCTime | minDeltaGCTime PS MarkSweep | 0 | 0 | 0 | 0.000s | 0.000s | 0.000s PS Scavenge | 5 | 5 | 5 | 0.087s | 0.087s | 0.087s2022-04-13 14:49:00.323 [job-0] INFO JobContainer - PerfTrace not enable!2022-04-13 14:49:00.324 [job-0] INFO StandAloneJobContainerCommunicator - Total 199722 records, 13382939 bytes | Speed 653.46KB/s, 9986 records/s | Error 16 records, 2145 bytes | All Task WaitWriterTime 9.765s | All Task WaitReaderTime 0.584s | Percentage 100.00%2022-04-13 14:49:00.325 [job-0] INFO JobContainer -任务启动时刻 : 2022-04-13 14:48:38任务结束时刻 : 2022-04-13 14:49:00任务总计耗时 : 21s任务平均流量 : 653.46KB/s记录写入速度 : 9986rec/s读出记录总数 : 199722读写失败总数 : 16","tags":[]},{"title":"反射","date":"2023-02-13T03:43:23.000Z","path":"2023/02/13/yuque/muoy6q0tleks7bgu/","text":"getType 返回类型是 Class （Class 是 Type 的子类）。 返回值无泛型信息 getGenericType 返回类型是 Type 若 Field 涉及到泛型，返回结果中有泛型信息 image.png image.png https://www.letianbiji.com/java-reflection-generics/java-Field-getType-getGenericType.html","tags":[]},{"title":"小灰的算法之旅读书笔记","date":"2023-02-13T02:55:45.000Z","path":"2023/02/13/yuque/kt77pz65hcba69id/","text":"image.png","tags":[]},{"title":"Dubbo SPI","date":"2022-05-12T07:41:54.000Z","path":"2022/05/12/yuque/apgq6m/","text":"Java SPI 机制实例演示Java 中 SPI 机制使用 ServiceLoader 实现，定义接口的实现，在 classpath resources 文件夹下创建 META-INF&#x2F;services 文件夹，以接口名称为文件名创建文件，输入接口实现类的类名 image.png 123456789101112131415161718192021222324252627public class Main &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Log&gt; serviceLoader = ServiceLoader.load(Log.class); Iterator&lt;Log&gt; iterator = serviceLoader.iterator(); while (iterator.hasNext()) &#123; Log log = iterator.next(); log.log(\"JDK SPI\"); &#125; &#125;&#125;// 输出如下:// Log4j:JDK SPI// Logback:JDK SPI 实现原理调用方法 java.util.ServiceLoader#load(java.lang.Class) 获取当前线程的 classLoader，调用 java.util.ServiceLoader#load(java.lang.Class, java.lang.ClassLoader) 创建 ServiceLoder 对象，调用 java.util.ServiceLoader#reload 清空 providers，providers 为存储接口实现类的 map \u0000 image.png","tags":[]},{"title":"基础支撑层——反射工具箱","date":"2021-04-13T09:11:58.000Z","path":"2021/04/13/yuque/hci4fo/","text":"代码位于 org.apache.ibatis.reflection reflectorThis class represents a cached set of class definition information thatallows for easy mapping between property names and getter&#x2F;setter methods._缓存类的元数据信息，管理类的属性和方法，提高反射的效率 image.png Reflector 创建核心流程即传入 Class 对象并解析填充 Reflector 的各个属性 type 传入 Class 对象 通过反射获取 Class 对象的所有构造方法，遍历获取无参构造方法初始化 defaultConstructor 见 org.apache.ibatis.reflection.Reflector#addDefaultConstructor","tags":[]},{"title":"架构概览","date":"2021-04-13T08:45:07.000Z","path":"2021/04/13/yuque/fqegg6/","text":"MyBatis 分为三层架构，分别是基础支撑层、核心处理层和接口层 基础支撑层 image.png 类型转换 比如 typeAlias 的应用 JdbcType 和 JavaType 的转换等 日志模块 排查问题 优化等 反射工具模块 在 Java 反射的基础上封装了反射工具 缓存 Java 原生的反射相关元信息提升反射的效率 binding 模块 自动生成 Mapper 接口的动态代理对象 数据源模块 数据源实现和三方数据源集成接口 缓存模块 解析器模块 主要提供对配置文件的解析 对 Mapper.xml 文件的解析 事务管理模块 image.png 核心处理层涉及 MyBatis 的初始化和一条 SQL 的全流程 配置解析 将配置文件 mapper 文件等配置信息解析后封装成 Configuration 对象 SQL 解析和 scripting 模块 动态生成 SQL SQL 执行 在 MyBatis 中，要执行一条 SQL 语句，会涉及非常多的组件，比较核心的有：Executor、StatementHandler、ParameterHandler 和 ResultSetHandler image.png 插件","tags":[]},{"title":"Slf4j源码浅析","date":"2019-05-30T17:03:50.000Z","path":"2019/05/31/Slf4j源码浅析/","text":"问题复现在项目中引入一个二方包后在后台日志诡异的不见了，于是使用 mvn dependency:tree -l tree.txt 输出依赖关系树，并定位到新引入的二方包部分,二方包引入了spring-boot-starter-logging其依赖了logback-classic与项目中的log4j产生了冲突，所以将前者排掉就项目就可以正常启动了，这个排包的过程不算难，那slf4j是如何实现绑定的呢？ slf4j源码浅析这里使用到的slf4j-api版本是1.7.25，在老版本中是存在一些线程安全问题的，通常我们打日志的时候都会写一段这样的代码 1private static final Logger logger = LoggerFactory.getLogger(XXX.class) 我们从LoggerFactory这个类开始分析源码,首先看到getLogger方法 12345678public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); .....&#125;public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 从上面源码可以看到会调用getLogger(String name)这个方法，通过LoggerFactory最终获取Logger对象，所以重点就是获取LoggerFactory. 我们重点看下 getILoggerFactory这个方法 1234567891011121314151617181920212223 public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(\"Unreachable code\");&#125; 从源码中可以看到INITIALIZATION_STATE是一个静态的volatile变量，在之前的版本中没有volatile修饰，在这个方法中主要就是调用了performInitialization方法完成初始化,在该方法中主要完成绑定工作并进行检查 123456789101112131415161718192021222324private final static void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125; &#125; private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; if (!isAndroid()) &#123; staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // the next line does the binding StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; ... 其中有个重要的方法findPossibleStaticLoggerBinderPathSet 顾名思义就是找可能存在的StaticLoggerBinder路径 1234567891011121314151617181920212223private static String STATIC_LOGGER_BINDER_PATH = \"org/slf4j/impl/StaticLoggerBinder.class\"; static Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() &#123; // use Set instead of list in order to deal with bug #138 // LinkedHashSet appropriate here because it preserves insertion order // during iteration Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet&lt;URL&gt;(); try &#123; ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader(); Enumeration&lt;URL&gt; paths; if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125; &#125; ... return staticLoggerBinderPathSet; &#125; 其实就是找日志实现包中的的StaticLoggerBinder，如slf4j-log4j12中的，将这些类的类路径添加到上面的set中，接着通过reportMultipleBindingAmbiguity方法检查是不是存在多个日志实现绑定产生冲突, 即看一下binderPathSet中元素个数是不是大于1，很简单，因此当项目中logback和slf4j-log4j同时存在时会打印出多个”Found binding in …” 12345678910111213private static boolean isAmbiguousStaticLoggerBinderPathSet(Set&lt;URL&gt; binderPathSet) &#123; return binderPathSet.size() &gt; 1; &#125; private static void reportMultipleBindingAmbiguity(Set&lt;URL&gt; binderPathSet) &#123; if (isAmbiguousStaticLoggerBinderPathSet(binderPathSet)) &#123; Util.report(\"Class path contains multiple SLF4J bindings.\"); for (URL path : binderPathSet) &#123; Util.report(\"Found binding in [\" + path + \"]\"); &#125; Util.report(\"See \" + MULTIPLE_BINDINGS_URL + \" for an explanation.\"); &#125; &#125; 回到bind方法，看到StaticLoggerBinder.getSingleton();，其实就是创建一个单例的StaticLoggerBinder对象，而这个对象中含有一个LoggerFactory，针对不同的日志框架有不同的实现 log4j1234567891011private final ILoggerFactory loggerFactory;private StaticLoggerBinder() &#123; loggerFactory = new Log4jLoggerFactory(); try &#123; Level level = Level.TRACE; &#125; catch (NoSuchFieldError nsfe) &#123; Util .report(\"This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version\"); &#125;&#125; logback-classic1234567private boolean initialized = false;private LoggerContext defaultLoggerContext = new LoggerContext();private final ContextSelectorStaticBinder contextSelectorBinder = ContextSelectorStaticBinder.getSingleton();private StaticLoggerBinder() &#123; defaultLoggerContext.setName(CoreConstants.DEFAULT_CONTEXT_NAME);&#125; 通过这种绑定的方式就可以实现LoggerFactory的获取，如引入了log4j，就会利用log4j实现的StaticLoggerBinder类来获取log4j的LoggerFactory,而LoggerFactory可以简单地理解为一个Map，key为loggerName,value为Logger对象","tags":[{"name":"Java","slug":"Java","permalink":"https://xiaoysec.github.io/tags/Java/"},{"name":"slf4j","slug":"slf4j","permalink":"https://xiaoysec.github.io/tags/slf4j/"}]}]