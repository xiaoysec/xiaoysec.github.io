[{"title":"语雀文章同步Hexo","date":"2023-02-20T05:34:21.000Z","path":"2023/02/20/语雀文章同步Hexo/","text":"前提条件搭建好 Hexo 博客环境 配置步骤插件源码地址 https://github.com/x-cold/yuque-hexo 安装 npm install -g yuque-hexo –save 配置 修改博客根目录下的 package.json 文件 12345678910111213141516171819\"yuqueConfig\": &#123; \"postPath\": \"source/_posts\", \"cachePath\": \"yuque.json\", \"mdNameFormat\": \"slug\", \"adapter\": \"hexo\", \"concurrency\": 5, \"baseUrl\": \"https://www.yuque.com/api/v2\", \"login\": \"xituchengxiaoyang\", \"repo\": \"blog\", \"token\": \"语雀token\", \"onlyPublished\": true, \"onlyPublic\": true&#125;,\"devDependencies\": &#123; \"yuque-hexo\": \"^1.6.0\"&#125;,\"hexo\": &#123; \"version\": \"4.2.1\"&#125;, 参数解释 参数名 含义 默认值 postPath 文档同步后生成的路径 source&#x2F;_posts&#x2F;yuque cachePath 文档下载缓存文件 yuque.json mdNameFormat 文件名命名方式 (title &#x2F; slug) title adapter 文档生成格式 (hexo&#x2F;markdown) hexo concurrency 下载文章并发数 5 baseUrl 语雀 API 地址 - login 语雀 login (group), 也称为个人路径 - repo 语雀仓库短名称，也称为语雀知识库路径 - onlyPublished 只展示已经发布的文章 false onlyPublic 只展示公开文章 false baseUrl 是固定的照抄就行，mdNameFormat 建议使用 title，repo 信息在这边看 image.png Token 需要设置一下 image.png 在 package.json 中配置 scripts 12345//添加以下命令行&#123; \"sync\": \"yuque-hexo sync\", \"clean:yuque\": \"yuque-hexo clean\"&#125; 完整的 package.json 文件如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#123; \"name\": \"hexo-site\", \"version\": \"0.0.0\", \"private\": true, \"scripts\": &#123; \"build\": \"hexo generate\", \"clean\": \"hexo clean\", \"deploy\": \"hexo deploy\", \"server\": \"hexo server\", \"sync\": \"yuque-hexo sync\", \"clean:yuque\": \"yuque-hexo clean\" &#125;, \"hexo\": &#123; \"version\": \"4.2.1\" &#125;, \"dependencies\": &#123; \"hexo\": \"^4.2.1\", \"hexo-deployer-git\": \"^4.0.0\", \"hexo-generator-archive\": \"^2.0.0\", \"hexo-generator-category\": \"^2.0.0\", \"hexo-generator-feed\": \"^3.0.0\", \"hexo-generator-index\": \"^3.0.0\", \"hexo-generator-json-content\": \"^4.2.3\", \"hexo-generator-tag\": \"^2.0.0\", \"hexo-helper-qrcode\": \"^1.0.2\", \"hexo-renderer-ejs\": \"^2.0.0\", \"hexo-renderer-less\": \"^4.0.0\", \"hexo-renderer-marked\": \"^6.0.0\", \"hexo-renderer-stylus\": \"^2.1.0\", \"hexo-server\": \"^3.0.0\", \"hexo-theme-landscape\": \"^0.0.3\", \"yuque-hexo\": \"^1.9.5\" &#125;, \"devDependencies\": &#123; \"yuque-hexo\": \"^1.9.5\" &#125;, \"yuqueConfig\": &#123; \"postPath\": \"source/_posts/yuque\", \"cachePath\": \"yuque.json\", \"mdNameFormat\": \"title\", \"adapter\": \"hexo\", \"concurrency\": 5, \"baseUrl\": \"https://www.yuque.com/api/v2\", \"login\": \"XXXXX\", //你自己的用户名 \"repo\": \"XXXX\", //你自己的仓库名 \"token\": \"XXXXX\", //你自己的token \"onlyPublished\": false, \"onlyPublic\": false &#125;&#125; 同步命令 yuque-hexo sync 同步yuque-hexo clean 清楚本地缓存 一些坑 语雀图片无法正常显示 因为语雀图片防盗链机制，图片无法正常显示，需要对主题下的文件做一点修改如我使用的 indigo，需要修改 themes&#x2F;indigo&#x2F;layout&#x2F;_partial&#x2F;head.ejs ，添加如下的源码 1&lt;meta name=\"referrer\" content=\"no-referrer\" /&gt; 部署出错，kex_exchange_identification: Connection closed by remote github 22 端口 timeout,直接使用 443 端口解决，在**~&#x2F;.ssh&#x2F;config **文件中添加如下 1234Host github.comHostName ssh.github.comUser gitPort 443 在命令行工具中使用代理 在.zshrc 或者.bash_profile 中添加如下命令，后重新加载环境变量，需要使用到梯子只需要先执行 on_proxy 123456789101112131415function on_proxy() &#123; export no_proxy=\"localhost,127.0.0.1,localaddress,.localdomain.com\" export http_proxy=\"http://127.0.0.1:9850\" export https_proxy=$http_proxy export all_proxy=socks5://127.0.0.1:9850 echo -e \"\\n\" echo -e \"proxy is on\"&#125;function off_proxy()&#123; unset http_proxy unset https_proxy unset all_proxy echo -e \"proxy is off\"&#125; mac 下查看 clash 中的代理信息如下 image.png 不要使用 ping www.google.com来进行测试，因为ping命令使用的是ICMP协议，是不支持代理的。 参考文章[1] http://www.manongjc.com/detail/61-xmojtxvddsuftbg.html[2] https://cloud.tencent.com/developer/article/2114329[3] https://cloud.tencent.com/developer/article/2168702[4] https://zhuanlan.zhihu.com/p/577256660","tags":[{"name":"效率工具","slug":"效率工具","permalink":"https://xiaoysec.github.io/tags/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"},{"name":"Hexo","slug":"Hexo","permalink":"https://xiaoysec.github.io/tags/Hexo/"}]},{"title":"召回系统在海拍客的实践","date":"2023-02-20T01:51:17.000Z","path":"2023/02/20/召回系统在海拍客的实践/","text":"前言推荐系统通常可以分为召回、粗排、精排、重排四个阶段，召回主要是根据不同策略或模型从海量的物品库中快速筛选出一小部分用户可能感兴趣的物品，交由排序模型来精准地完成个性化排序，本文主要阐述召回在算法侧的工作原理以及召回系统工程侧落地实践。 召回算法目前算法团队在使用传统算法如 ItemCF、Swing 的基础上，也在不断尝试在召回中应用深度模型，下面章节介绍目前算法团队使用到的几种典型召回算法原理，实际的模型会更复杂但原理大同小异。 协同过滤作为在推荐系统召回中最基本的一种算法，系统过滤主要分为两大类 基于用户的协同过滤算法(UserCF) 基于物品的协同过滤算法(ItemCF) 基于用户的协同过滤简单的说基于用户的协同过滤就是找到与你相似的用户，将相似用户交互过的商品推荐给你。基于用户的协同过滤核心在于计算用户的相似度，以一个简单的例子演示该算法假设我们在做首页商品推荐，用户 A 点击的商品集合为 M，用户 B 点击的商品集合为 N,那么用户 A 和用户 B 的相似度可以通过如下公式计算 image.png 如用户 A 点击过的商品集合 M &#x3D; {a,b,c,d} , 用户 B 点击过的商品集合 N&#x3D;{a,b,c,d,e,f} ，所以用户 A 和用户 B 的相似度为 2&#x2F;3，用户 C 点击过的商品集合为{a,b,c} ，用户 D 点击过的商品集合为{a,b}，此处我们人为定义相似度阈值为 0.5，那么与用户 A 相似的用户为用户 B 和用户 C，那么可以给用户 A 推荐商品{e,f}，给用户 C 推荐{d,e,f}。 这里只是展示了一种比较简单粗暴的方法，想要得到更好的推荐效果可以改进相似度的计算方法，这边不作深究。 基于物品的协同过滤简单来说基于物品的协同过滤就是根据用户对商品的交互历史，推荐该商品相似的其他商品。基于物品的协同过滤同样需要计算物品的相似度，以一个简单的例子演示该算法假设喜欢物品 a 的用户数量为 N(a)，喜欢物品 b 的用户数量为 N(b) ，那么物品 a 和物品 b 的相似度可以使用如下公式表示 image.png 假设用户对商品的喜好如下表所示 商品a 商品 b 商品 c 商品 d 用户A ✅ ✅ ✅ 用户B ✅ ✅ ✅ 用户C ✅ ✅ 那么根据上述的相似度计算公式可以得到ab 相似度为 0.71 ，ac 相似度为 0.58，bc 相似度为 0.82，cd 相似度为 0.82我们人为假定某个用户对商品 a 有购买行为兴趣度为 10，对 b 商品有点击行为兴趣度为 5，那么我们可以得到该用户对商品 c 的兴趣度为 10 _ 0.58 + 5 _ 0.82 &#x3D; 9.9，对 d 的兴趣度为 0 ，因此可以给该用户推荐商品 c image.png 双塔模型双塔模型是一种在推荐领域召回、粗排阶段被广泛使用的深度学习模型，其结构非常简单如下图所示 image.png 左侧是 User 塔，右侧是 Item 塔，可将特征拆分为两大类：用户相关特征（用户基本信息、群体统计属性以及行为过的 Item 序列等）与 Item 相关特征（Item 基本信息、属性信息等），原则上，Context 上下文特征可以放入用户侧塔。对于这两个塔本身，则是经典的 DNN 模型，从特征 OneHot 到特征 Embedding，再经过几层 MLP 隐层，两个塔分别输出用户 Embedding 和 Item Embedding 编码。训练阶段，User Embedding 和 Item Embedding 做内积或者 Cosine 相似度计算，使得用户和正例 Item 在 Embedding 空间更接近，和负例 Item 在 Embedding 空间距离拉远，损失函数则可用标准交叉熵损失。在线服务阶段，对于海量的 Item 集合，可以通过 Item 侧塔，离线将所有 Item 转化成 Embedding，并存储进 ANN 检索系统如 Faiss 以供查询。当一个用户进行请求时，将用户最新行为过的 Item 作为用户侧塔的输入，然后通过用户侧塔打出 User Embedding，从 Faiss 库里拉取相似性得分 Top K 的 Item，做为个性化召回结果这种模式。这样也可以实时地体现用户即时兴趣的变化，这是特征实时的角度，做起来相对简单。 image.png 本章小结目前算法侧通过离线的方式训练召回数据，存储到对应的数据源中，工程侧需要通过召回配置完成多路召回-去重-过滤-融合的操作，将召回结果送到下一阶段进行个性化排序，对整个推荐链路而言，召回要求快，排序要求准，所以对召回系统的要求是稳定低延迟。 image.png 召回工程海拍客推荐目前服务触达、首页、搜索激活页、支付成功页、 我的页面等多个场景，涵盖了购前、购中、购后等多个不同阶段。如上面所述，商品召回作为推荐的第一步在整个推荐流程中起到了举足轻重的作用，直接影响了返回物料的质量，而合理的召回工程架构也一定程度上影响业务和算法迭代的速度与质量。 召回初代架构由于业务的特殊性以及诸多历史遗留问题，在之前海拍客的推荐架构中各业务系统需要各自完成商品召回，再按需调用精排服务完成商品排序等后续操作，召回数据源又各有不同，如触达业务使用了 MySQL 作为召回数据源，推荐业务使用了 Redis 作为主要的召回数据源，所涉及到的架构大致如下图所示 image.png 架构局限性这种架构在业务的迭代中也逐渐出现各种弊端 职责不清晰， 从整个推荐域看，这种架构增加了业务系统复杂度使得业务系统过重，系统和系统之间架构职责不清晰 扩展性差，依赖各业务系统各自完成召回动作，而商品召回本身并不是一个简单动作，需要完成召回-过滤-融合等一系列动作。除此以外，数据源的新增变更、数据结构的变化带来的适配工作也是一个让人头疼的问题 召回配置难，这一点是对算法同学而言的，原有架构缺少一个统一的召回配置平台，AB 实验的进行和验证受到影响，妨碍算法迭代效率提升 稳定性难保障，对平台开发同学而言，日常需要监控依赖数据源、召回的各个阶段，如数据源平均 rt，各阶段平均 rt、超时率，召回整体的兜底率等指标，业务系统越多越不利于监控，系统的稳定性也会大打折扣 召回系统设计基于如上所述的诸多缺点，我们着手完成了推荐召回的服务切分，使得触达、首页推荐、购后等多个场景的推荐业务召回部分能够得到统一 主体设计一般来说，整个召回阶段主要完成多路召回-过滤-去重-融合几个步骤，大致的作用如下 多路召回，根据配置采用不同的召回策略从不同的数据源中获取物料，原则上多路召回尽可能多的返回用户可能有兴趣的物料，通常会根据每路召回的后验表现来设置配比。 去重，这一步主要是针对每一路召回而言，通常只是简单的根据商品 id 或者一些简单属性去重，避免因为数据源清洗问题导致的重复曝光。 过滤，通常会存在一些不同的过滤规则，如用户维度的曝光过滤、点击过滤、购买过滤等，也可能是基于风控规则的过滤，如卖家作弊等处罚、黄图恶心图等过滤。 融合，多路召回的物料根据需要进行合并，截断选取若干物料进入下一阶段，可以按照召回策略优先级融合，也可以是多路召回投票融合，也可以是通过物料的指标权重融合。 针对上述召回系统的几个步骤和特性，我们设计了如下的系统架构，整个召回系统大体上可以分为三层，召回配置层、召回引擎层、数据依赖层。 image.png 召回配置层 召回配置层主要面向算法同学，旨在让算法同学方便快捷地进行召回层配置进行 AB 实验和后续的结果验证，在实现上，主要借助 Disconf 作为配置中心，在引擎层做 AB 分流、召回配置解析等前置操作。 召回引擎层 召回引擎层采用模块化设计，通过召回配置实现模块和任务节点的动态化编排，同时通过插件化思想提供了异构数据源的支持，大大降低了新增数据源的成本。在稳定性保障上，由于采用了模块-任务节点的设计，能够很好地实现多维度的监控，如场景-模块维度的 rt 监控、失败率监控，场景-任务节点维度的超时率监控，场景维度的兜底率、无结果率监控等，同时配合钉钉告警实现问题的早发现早止血。 召回存储层 召回存储层主要面向异构数据源设计，前面提到因为历史原因现有的召回数据源结构和存储介质都存在差异以满足不同业务系统的诉求，因此在改造召回系统的过程中需要充分考虑数据存储的问题，如首页推荐等场景召回数据结构相对简单，需要满足低延迟诉求所以一直以来优先考虑 Redis, 又如触达算法召回数据结构复杂，包含属性多，数据量大用 MySQL 或者 MongoDB 更合适些，又如后续业务可能存在向量召回的场景，使用 ElasticSearch 或者调用 faiss 服务更合适，因此必须要考虑异构数据源的接入便捷性。 实现细节这一节主要介绍下召回引擎部分的一些实现细节以及踩过的一些坑，整个召回召回引擎调度如下图所示 image.png 模块化设计 如上述，整个召回过程中大体经过了多路召回-去重-过滤-融合等步骤。在设计上可以将各个步骤封装成独立的模块(module)，AB 分流获取门店对应的召回配置后，根据配置编排所需要的模块完成调度。而模块和模块之间又可能存在依赖关系，如在召回系统中各模块之间是串行的，而在一些系统中存在模块并发执行的需求，所以在设计之初设计了如下结构来做兼容，简单来说同一个列表内多个模块并发执行，不同列表的模块串行执行。 image.png 在模块内，抽象出任务节点(TaskNode)，如在多路召回模块中，每一路召回相当于一个任务节点，彼此并发执行，又比如在过滤模块中，每一种过滤策略可以当做一个任务节点获取待过滤数据。通过任务节点并发的方式可以有效降低 RT,相较于之前串行召回的方式平均减少 RT 约 16%。如下代码大致演示了模块内任务节点执行的实现。 image.png 1234567891011121314151617181920212223242526272829303132/** * 模块执行只需要执行任务列表中的任务即可 * 任务列表中的任务先暂时都并发执行 后面可以支持并发和顺序两种模式 * 即 [[A,B],[C]] A、B并发执行完成后再执行C * * @param requestContext 召回请求上下文 * @return recallModuleResultDto 召回模块结果对象 */@Overridepublic ModuleResult invoke(RequestContext requestContext) &#123; RecallStrategyConfig recallStrategyConfig = requestContext.getRecallStrategyConfig(); if (recallStrategyConfig == null) &#123; return null; &#125; ModuleResult moduleResult = new ModuleResult(); moduleResult.setTaskResultList(new ArrayList&lt;&gt;()); if (CollectionUtils.isEmpty(this.taskList)) &#123; return moduleResult; &#125; // 并发执行任务列表中的任务 使用arrayList保留任务原始的顺序 List&lt;Tuple&lt;TaskNode, CompletableFuture&lt;TaskResult&gt;&gt;&gt; tupleList = new ArrayList&lt;&gt;(); for (TaskNode taskNode : taskList) &#123; CompletableFuture&lt;TaskResult&gt; future = CompletableFuture.supplyAsync(() -&gt; taskNode.invoke(requestContext), ThreadUtil.executor); tupleList.add(new Tuple&lt;&gt;(taskNode, future)); &#125; // 结果获取 省略... return moduleResult;&#125; 模块内多个任务节点并发执行有一些需要关注的点，在实现中可能需要特别关注。 任务节点超时处理， 首先任务节点必须配置超时时间，避免因为某一个任务节点引起的服务雪崩，其次不同的任务节点其超时时间可以根据经验做配置化，如多路召回中 MongoDB 和 Redis 的超时时间可以根据监控做动态化调整，再比如对于无执行先后顺序要求的任务节点可以适当调整获取结果顺序以避免空结果等。 召回结果在不同阶段的传递，在目前的召回引擎实现中采用了上下文的方式传递召回中间结果，上下文中会保存不同阶段的模块结果(其中包含各阶段的召回结果)，保存不同阶段召回结果即每个阶段召回结果均为深拷贝以避免对上一个模块结果的破坏。 空结果处理， 在实际运行中可能存在各种情况导致召回结果为空，此时需要进行服务端兜底召回，除此以外当常规召回数量不够也需要使用兜底数据补召回，兜底召回数据请求实际也需要权衡，目前的实现中把兜底召回作为一路召回在多路并发召回阶段执行，通过多一次 IO 来降低服务的总 RT(兜底召回不一定被使用) 异构数据源支持 召回引擎提供了对多种数据源的支持，目前已支持如 Redis、MySQL、MongoDB、RPC 等多种数据源。以触达算法召回为例，数据量大且字段属性多，非常适合以 MongoDB 作为存储数据源，而首页推荐、购后推荐等场景的召回数据大多结构简单且要求召回速度快，因此以 Redis 作为存储数据源更合适。常规的单路召回需要经过获取数据-去重-截断-类型转换等步骤，其中获取数据和类型转换需要根据数据源类型做适配，因此在设计之初采用插件的方式支持异构数据源，只要实现几个简单方法就可以完成数据源的新增，如下代码大致展示了数据源插件的抽象定义 1234567891011121314151617public abstract class AbstractRecaller&lt;OriginType, ResultType&gt; implements Recaller&lt;OriginType, ResultType&gt; &#123; //部分代码省略 @Override public ResultType recall(RequestContext requestContext, RecallSourceConfig recallSourceConfig) &#123; // 获取数据源数据 OriginType originData = fetch(requestContext, recallSourceConfig); // 去重 originData = distinct(originData); // 截断 originData = cut(originData, recallSourceConfig.getLen()); // 转换 ResultType result = convert(originData, recallSourceConfig); return result; &#125;&#125; 以一个实际的单路召回为例，召回策略配置如下，表示该路召回策略存储数据源为 MongoDB，召回类型为 s2i，召回的主键标识为 actnew_sign,同时需要返回对应文档的指定字段 12345mongo_act_new_sign: dataSource: mongo fields: itemId,shopId,feature,rankNum,orderedDays key: act_new_sign_ type: recall_s2i 在运行的过程中召回引擎先会根据召回类型、绑定的数据源元信息等匹配对应的召回器 Recaller, 召回器的注册使用自定义注解@AiRecaller 完成，如下代码即为以 MongoDB 作为数据源的接入方式。 123456789101112131415161718192021222324252627282930@AiRecaller( name = \"touchMongoRecaller\", dataSourceType = RecallDataSourceType.mongo, recallTypes = &#123;RecallType.recall_s2i&#125;, dbName = \"ai_recall\", tableName = \"ai_touch\")public class TouchMongoRecaller extends AbstractRecaller&lt;List&lt;TouchRecallDo&gt;, TriggerResult&gt; &#123; @Resource private MongoTemplate mongoTemplate; @Override public List&lt;TouchRecallDo&gt; fetch(RequestContext requestContext, RecallSourceConfig recallSourceConfig) &#123; String sceneId = requestContext.getRecallReq().getSceneId(); String recallKey = recallSourceConfig.getKey(); String shopId = requestContext.getRecallReq().getShopId(); // 查询 List&lt;TouchRecallDo&gt; touchRecallDos = null; Query query = new Query(); // TODO 这边可以结合管理后台实现查询条件的配置化 query.addCriteria(Criteria.where(\"shop_id\").is(shopId)) .addCriteria(Criteria.where(\"recall_key\").is(recallKey)) .with(Sort.by(Sort.Order.asc(\"rank_num\"))); try &#123; touchRecallDos = mongoTemplate.find(query, TouchRecallDo.class); &#125; catch (Exception e) &#123; logger.error(\"[TouchMongoRecaller-fetch] sceneId:&#123;&#125; recallKey:&#123;&#125; shopId:&#123;&#125; exception cause:\", sceneId, recallKey, shopId, e); &#125; return touchRecallDos; &#125; 需要说明的是目前召回引擎多以离线方式计算落库，实时召回也多以用户实时 Query 等作为 trigger，但现有的召回系统架构可以快速支持如基于向量的实时召回等方式，这也是后续召回引擎一个迭代的方向。 总结和展望如上文提及，目前算法侧的召回数据均以离线方式产出落库，因此对实时特征的利用相对不足。后续召回引擎可以结合特征平台建设，尝试基于 ElasticSearch 或者 Faiss 的在线检索召回服务。 文献引用推荐系统技术演进趋势：从召回到排序再到重排SENet 双塔模型：在推荐领域召回粗排的应用及其它","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://xiaoysec.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"系统设计","slug":"系统设计","permalink":"https://xiaoysec.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"召回","slug":"召回","permalink":"https://xiaoysec.github.io/tags/%E5%8F%AC%E5%9B%9E/"}]},{"title":"Slf4j源码浅析","date":"2019-05-30T17:03:50.000Z","path":"2019/05/31/Slf4j源码浅析/","text":"问题复现在项目中引入一个二方包后在后台日志诡异的不见了，于是使用 mvn dependency:tree -l tree.txt 输出依赖关系树，并定位到新引入的二方包部分,二方包引入了spring-boot-starter-logging其依赖了logback-classic与项目中的log4j产生了冲突，所以将前者排掉就项目就可以正常启动了，这个排包的过程不算难，那slf4j是如何实现绑定的呢？ slf4j源码浅析这里使用到的slf4j-api版本是1.7.25，在老版本中是存在一些线程安全问题的，通常我们打日志的时候都会写一段这样的代码 1private static final Logger logger = LoggerFactory.getLogger(XXX.class) 我们从LoggerFactory这个类开始分析源码,首先看到getLogger方法 12345678public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); .....&#125;public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 从上面源码可以看到会调用getLogger(String name)这个方法，通过LoggerFactory最终获取Logger对象，所以重点就是获取LoggerFactory. 我们重点看下 getILoggerFactory这个方法 1234567891011121314151617181920212223 public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(\"Unreachable code\");&#125; 从源码中可以看到INITIALIZATION_STATE是一个静态的volatile变量，在之前的版本中没有volatile修饰，在这个方法中主要就是调用了performInitialization方法完成初始化,在该方法中主要完成绑定工作并进行检查 123456789101112131415161718192021222324private final static void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125; &#125; private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; if (!isAndroid()) &#123; staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // the next line does the binding StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; ... 其中有个重要的方法findPossibleStaticLoggerBinderPathSet 顾名思义就是找可能存在的StaticLoggerBinder路径 1234567891011121314151617181920212223private static String STATIC_LOGGER_BINDER_PATH = \"org/slf4j/impl/StaticLoggerBinder.class\"; static Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() &#123; // use Set instead of list in order to deal with bug #138 // LinkedHashSet appropriate here because it preserves insertion order // during iteration Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet&lt;URL&gt;(); try &#123; ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader(); Enumeration&lt;URL&gt; paths; if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125; &#125; ... return staticLoggerBinderPathSet; &#125; 其实就是找日志实现包中的的StaticLoggerBinder，如slf4j-log4j12中的，将这些类的类路径添加到上面的set中，接着通过reportMultipleBindingAmbiguity方法检查是不是存在多个日志实现绑定产生冲突, 即看一下binderPathSet中元素个数是不是大于1，很简单，因此当项目中logback和slf4j-log4j同时存在时会打印出多个”Found binding in …” 12345678910111213private static boolean isAmbiguousStaticLoggerBinderPathSet(Set&lt;URL&gt; binderPathSet) &#123; return binderPathSet.size() &gt; 1; &#125; private static void reportMultipleBindingAmbiguity(Set&lt;URL&gt; binderPathSet) &#123; if (isAmbiguousStaticLoggerBinderPathSet(binderPathSet)) &#123; Util.report(\"Class path contains multiple SLF4J bindings.\"); for (URL path : binderPathSet) &#123; Util.report(\"Found binding in [\" + path + \"]\"); &#125; Util.report(\"See \" + MULTIPLE_BINDINGS_URL + \" for an explanation.\"); &#125; &#125; 回到bind方法，看到StaticLoggerBinder.getSingleton();，其实就是创建一个单例的StaticLoggerBinder对象，而这个对象中含有一个LoggerFactory，针对不同的日志框架有不同的实现 log4j1234567891011private final ILoggerFactory loggerFactory;private StaticLoggerBinder() &#123; loggerFactory = new Log4jLoggerFactory(); try &#123; Level level = Level.TRACE; &#125; catch (NoSuchFieldError nsfe) &#123; Util .report(\"This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version\"); &#125;&#125; logback-classic1234567private boolean initialized = false;private LoggerContext defaultLoggerContext = new LoggerContext();private final ContextSelectorStaticBinder contextSelectorBinder = ContextSelectorStaticBinder.getSingleton();private StaticLoggerBinder() &#123; defaultLoggerContext.setName(CoreConstants.DEFAULT_CONTEXT_NAME);&#125; 通过这种绑定的方式就可以实现LoggerFactory的获取，如引入了log4j，就会利用log4j实现的StaticLoggerBinder类来获取log4j的LoggerFactory,而LoggerFactory可以简单地理解为一个Map，key为loggerName,value为Logger对象","tags":[{"name":"Java","slug":"Java","permalink":"https://xiaoysec.github.io/tags/Java/"},{"name":"slf4j","slug":"slf4j","permalink":"https://xiaoysec.github.io/tags/slf4j/"}]}]